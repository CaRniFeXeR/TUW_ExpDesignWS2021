{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from surprise import AlgoBase\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import NMF\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants and initialization\n",
    "item_threshold = 1 # 1 means no filtering\n",
    "my_seed = 0\n",
    "rd.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "predict_col = 'artist'\n",
    "top_fraction = 0.2\n",
    "user_events_file = 'data/user_events.csv'\n",
    "low_user_file = 'data/low_main_users.csv'\n",
    "medium_user_file = 'data/medium_main_users.csv'\n",
    "high_user_file = 'data/high_main_users.csv'\n",
    "performance_data_file = 'data/performance_data.csv'\n",
    "prediction_data_file = 'data/prediction_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of user events: 28718087\n"
     ]
    }
   ],
   "source": [
    "# read user events\n",
    "cols = ['user', 'artist', 'album', 'track', 'timestamp']\n",
    "df_events = pd.read_csv(user_events_file, sep='\\t', names=cols)\n",
    "print('No. of user events: ' + str(len(df_events)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. user-item interactions: 1755361\n"
     ]
    }
   ],
   "source": [
    "# create user-item matrix\n",
    "df_events = df_events.groupby(['user', predict_col]).size().reset_index(name='count')\n",
    "print('No. user-item interactions: ' + str(len(df_events)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021445</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021445</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021445</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021445</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021445</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  artist  count\n",
       "0  1021445      12     43\n",
       "1  1021445      16      1\n",
       "2  1021445      28      7\n",
       "3  1021445      29      1\n",
       "4  1021445      46      1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. filtered user events: 1755361\n",
      "No. filtered items: 352805\n"
     ]
    }
   ],
   "source": [
    "df_events = df_events[df_events['count'] >= item_threshold]\n",
    "print('No. filtered user events: ' + str(len(df_events)))\n",
    "print('No. filtered items: ' + str(len(df_events[predict_col].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean artists per user: 585.1203333333333\n",
      "Min artists per user: 18\n",
      "Max artists per user: 4011\n"
     ]
    }
   ],
   "source": [
    "# get user distribution\n",
    "user_dist = df_events['user'].value_counts()\n",
    "num_users = len(user_dist)\n",
    "print('Mean artists per user: ' + str(user_dist.mean()))\n",
    "print('Min artists per user: ' + str(user_dist.min()))\n",
    "print('Max artists per user: ' + str(user_dist.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. items: 352805\n"
     ]
    }
   ],
   "source": [
    "# get item distribution\n",
    "item_dist = df_events[predict_col].value_counts()\n",
    "num_items = len(item_dist)\n",
    "print('No. items: ' + str(num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. top items: 70561\n"
     ]
    }
   ],
   "source": [
    "# get top items\n",
    "num_top = int(top_fraction * num_items)\n",
    "top_item_dist = item_dist[:num_top]\n",
    "print('No. top items: ' + str(len(top_item_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of users: 3000\n"
     ]
    }
   ],
   "source": [
    "# read users\n",
    "low_users = pd.read_csv(low_user_file, sep=',').set_index('user_id')\n",
    "medium_users = pd.read_csv(medium_user_file, sep=',').set_index('user_id')\n",
    "high_users = pd.read_csv(high_user_file, sep=',').set_index('user_id')\n",
    "no_users = len(low_users) + len(medium_users) + len(high_users)\n",
    "print('No. of users: ' + str(no_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low count (for check): 1000\n",
      "Med count (for check): 1000\n",
      "High count (for check): 1000\n"
     ]
    }
   ],
   "source": [
    "# get pop fractions\n",
    "pop_count = [] # number of top items per user\n",
    "user_hist = [] # user history sizes\n",
    "pop_fraq = [] # relative number of top items per user\n",
    "pop_item_fraq = [] # average popularity of items in user profiles\n",
    "low_profile_size = 0\n",
    "low_gap = 0\n",
    "medium_profile_size = 0\n",
    "medium_gap = 0\n",
    "high_profile_size = 0\n",
    "high_gap = 0\n",
    "low_count = 0\n",
    "med_count = 0\n",
    "high_count = 0\n",
    "for u, df in df_events.groupby('user'):\n",
    "    no_user_items = len(set(df[predict_col])) # profile size\n",
    "    no_user_pop_items = len(set(df[predict_col]) & set(top_item_dist.index)) # top items in profile\n",
    "    pop_count.append(no_user_pop_items)\n",
    "    user_hist.append(no_user_items)\n",
    "    pop_fraq.append(no_user_pop_items / no_user_items)\n",
    "    # get popularity (= fraction of users interacted with item) of user items and calculate average of it\n",
    "    user_pop_item_fraq = sum(item_dist[df[predict_col]] / no_users) / no_user_items\n",
    "    pop_item_fraq.append(user_pop_item_fraq)\n",
    "    if u in low_users.index: # get user group-specific values\n",
    "        low_profile_size += no_user_items\n",
    "        low_gap += user_pop_item_fraq\n",
    "        low_count += 1\n",
    "    elif u in medium_users.index:\n",
    "        medium_profile_size += no_user_items\n",
    "        medium_gap += user_pop_item_fraq\n",
    "        med_count += 1\n",
    "    else:\n",
    "        high_profile_size += no_user_items\n",
    "        high_gap += user_pop_item_fraq\n",
    "        high_count += 1\n",
    "low_profile_size /= len(low_users)\n",
    "medium_profile_size /= len(medium_users)\n",
    "high_profile_size /= len(high_users)\n",
    "low_gap /= len(low_users)\n",
    "medium_gap /= len(medium_users)\n",
    "high_gap /= len(high_users)\n",
    "print('Low count (for check): ' + str(low_count))\n",
    "print('Med count (for check): ' + str(med_count))\n",
    "print('High count (for check): ' + str(high_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021445</td>\n",
       "      <td>12</td>\n",
       "      <td>184.222707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021445</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021445</td>\n",
       "      <td>28</td>\n",
       "      <td>27.174672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021445</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021445</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  artist       count\n",
       "0  1021445      12  184.222707\n",
       "1  1021445      16    1.000000\n",
       "2  1021445      28   27.174672\n",
       "3  1021445      29    1.000000\n",
       "4  1021445      46    1.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df_events = pd.DataFrame()\n",
    "for user_id, group in df_events.groupby('user'):\n",
    "    min_rating = group['count'].min()\n",
    "    max_rating = group['count'].max()\n",
    "    scaler = MinMaxScaler(feature_range=(1, 1000))\n",
    "    scaled_ratings = scaler.fit_transform(group['count'].values.reshape(-1, 1).astype(float))\n",
    "    new_rows = group.copy()\n",
    "    new_rows['count'] = scaled_ratings\n",
    "    scaled_df_events = scaled_df_events.append(new_rows)\n",
    "\n",
    "scaled_df_events.head()\n",
    "#scaled_df_events = scaled_df_events.set_index('user') # needed for new python/surprise version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min rating: 1.0\n",
      "Max rating: 1000.0000000000001\n"
     ]
    }
   ],
   "source": [
    "df_events = scaled_df_events\n",
    "print('Min rating: ' + str(df_events['count'].min()))\n",
    "print('Max rating: ' + str(df_events['count'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021445</td>\n",
       "      <td>12</td>\n",
       "      <td>184.222707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021445</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021445</td>\n",
       "      <td>28</td>\n",
       "      <td>27.174672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021445</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021445</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  artist       count\n",
       "0  1021445      12  184.222707\n",
       "1  1021445      16    1.000000\n",
       "2  1021445      28   27.174672\n",
       "3  1021445      29    1.000000\n",
       "4  1021445      46    1.000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(df_events['count'].min(), df_events['count'].max()))\n",
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df_events, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size = 0.2, random_state = my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_random(testset, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r in testset:\n",
    "        if len(top_n[uid]) == 0:\n",
    "            for i in range(0, 10):\n",
    "                top_n[uid].append((rd.choice(item_dist.index), i))\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_mp(testset, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r in testset:\n",
    "        if len(top_n[uid]) == 0:\n",
    "            for iid, count in item_dist[:n].items():\n",
    "                top_n[uid].append((iid, count))\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae_of_groups(predictions) -> pd.DataFrame:\n",
    "    print('All: ')\n",
    "    mae_all: float = accuracy.mae(predictions)\n",
    "    low_predictions = []\n",
    "    med_predictions = []\n",
    "    high_predictions = []\n",
    "    for uid, iid, true_r, est, details in predictions:\n",
    "        prediction = [(uid, iid, true_r, est, details)]\n",
    "        if uid in low_users.index:\n",
    "            low_predictions.append(accuracy.mae(prediction, verbose=False))\n",
    "        elif uid in medium_users.index:\n",
    "            med_predictions.append(accuracy.mae(prediction, verbose=False))\n",
    "        else:\n",
    "            high_predictions.append(accuracy.mae(prediction, verbose=False))\n",
    "\n",
    "    mae_low: float = np.mean(low_predictions)\n",
    "    mae_med: float = np.mean(med_predictions)\n",
    "    mae_high: float = np.mean(high_predictions)\n",
    "    print('LowMS: ' + str(mae_low))\n",
    "    print('MedMS: ' + str(mae_med))\n",
    "    print('HighMS: ' + str(mae_high))\n",
    "    print(stats.ttest_ind(low_predictions, high_predictions))\n",
    "\n",
    "    return pd.DataFrame({'mae_all': [mae_all], 'mae_low': [mae_low], 'mae_med': [mae_med], \n",
    "    'mae_high': [mae_high]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create item dataframe with normalized item counts\n",
    "df_item_dist = pd.DataFrame(item_dist)\n",
    "df_item_dist.columns = ['count']\n",
    "df_item_dist['count'] /= no_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:30: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:30: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:30: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\PREINS~1\\AppData\\Local\\Temp/ipykernel_19652/2237871758.py:30: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if algo_names[i] is not 'Random' and algo_names[i] is not 'MostPopular':\n",
      "C:\\Users\\PREINS~1\\AppData\\Local\\Temp/ipykernel_19652/2237871758.py:30: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if algo_names[i] is not 'Random' and algo_names[i] is not 'MostPopular':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "UserItemAvg\n",
      "All: \n",
      "MAE:  38.5612\n",
      "LowMS: 42.94802225638076\n",
      "MedMS: 33.90013072887102\n",
      "HighMS: 40.68639747115602\n",
      "Ttest_indResult(statistic=6.410087809223839, pvalue=1.4574568991380452e-10)\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "UserKNN\n",
      "All: \n",
      "MAE:  45.6320\n",
      "LowMS: 49.75989995441734\n",
      "MedMS: 42.483604584035085\n",
      "HighMS: 45.99103663278319\n",
      "Ttest_indResult(statistic=10.222608304056013, pvalue=1.591725927878542e-24)\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "UserKNNAvg\n",
      "All: \n",
      "MAE:  41.8842\n",
      "LowMS: 46.58083982804533\n",
      "MedMS: 37.58534841057563\n",
      "HighMS: 43.2426341108826\n",
      "Ttest_indResult(statistic=9.298158418965674, pvalue=1.4421913302650728e-20)\n",
      "NMF\n",
      "All: \n",
      "MAE:  34.8799\n",
      "LowMS: 38.422261572330434\n",
      "MedMS: 30.59632763636456\n",
      "HighMS: 37.28507455638233\n",
      "Ttest_indResult(statistic=2.8128361265486665, pvalue=0.004911127445176993)\n",
      "     mae_all    mae_low    mae_med   mae_high         algo\n",
      "0  38.561220  42.948022  33.900131  40.686397  UserItemAvg\n",
      "0  45.632008  49.759900  42.483605  45.991037      UserKNN\n",
      "0  41.884150  46.580840  37.585348  43.242634   UserKNNAvg\n",
      "0  34.879921  38.422262  30.596328  37.285075          NMF\n",
      "                                         UserItemAvg  \\\n",
      "0  (48778840, 3544, 3.5931213497728747, 7.0081346...   \n",
      "1  (21293881, 21510, 55.73972602739726, 38.304481...   \n",
      "2  (5696716, 96587, 118.21600000000001, 28.341889...   \n",
      "3  (47885122, 46721, 25.93434617471514, 39.974921...   \n",
      "4  (29745530, 1369, 5.933333333333334, 8.95974201...   \n",
      "\n",
      "                                             UserKNN  \\\n",
      "0  (48778840, 3544, 3.5931213497728747, 22.226520...   \n",
      "1  (21293881, 21510, 55.73972602739726, 24.735225...   \n",
      "2  (5696716, 96587, 118.21600000000001, 33.285563...   \n",
      "3  (47885122, 46721, 25.93434617471514, 123.67112...   \n",
      "4  (29745530, 1369, 5.933333333333334, 20.9282023...   \n",
      "\n",
      "                                          UserKNNAvg  \\\n",
      "0  (48778840, 3544, 3.5931213497728747, 1.0, {'ac...   \n",
      "1  (21293881, 21510, 55.73972602739726, 35.615519...   \n",
      "2  (5696716, 96587, 118.21600000000001, 30.048137...   \n",
      "3  (47885122, 46721, 25.93434617471514, 108.14865...   \n",
      "4  (29745530, 1369, 5.933333333333334, 7.56977486...   \n",
      "\n",
      "                                                 NMF  \n",
      "0  (48778840, 3544, 3.5931213497728747, 5.0395940...  \n",
      "1  (21293881, 21510, 55.73972602739726, 2.7681941...  \n",
      "2  (5696716, 96587, 118.21600000000001, 1.0, {'wa...  \n",
      "3  (47885122, 46721, 25.93434617471514, 8.4091590...  \n",
      "4  (29745530, 1369, 5.933333333333334, 1.06637564...  \n"
     ]
    }
   ],
   "source": [
    "sim_users = {'name': 'cosine', 'user_based': True}  # compute cosine similarities between users\n",
    "algos = [] # Random and MostPopular is calculated by default\n",
    "algos.append(None)#Random())\n",
    "algos.append(None)#MostPopular())\n",
    "algos.append(BaselineOnly())\n",
    "algos.append(KNNBasic(sim_options = sim_users, k=40))\n",
    "algos.append(KNNWithMeans(sim_options = sim_users, k=40))\n",
    "algos.append(NMF(n_factors = 15))\n",
    "algo_names = ['Random',\n",
    "              'MostPopular',\n",
    "              'UserItemAvg',\n",
    "              'UserKNN',\n",
    "              'UserKNNAvg',\n",
    "              'NMF']\n",
    "\n",
    "i = 0\n",
    "low_rec_gap_list = [] # one entry per algorithmus\n",
    "medium_rec_gap_list = []\n",
    "high_rec_gap_list = []\n",
    "performance_list: List[pd.DataFrame] = []\n",
    "all_predictions = {}\n",
    "\n",
    "for i in range(0, len(algo_names)):\n",
    "    df_item_dist[algo_names[i]] = 0\n",
    "    low_rec_gap = 0\n",
    "    medium_rec_gap = 0\n",
    "    high_rec_gap = 0\n",
    "\n",
    "    # get accuracy for personalized approaches\n",
    "    if algo_names[i] is not 'Random' and algo_names[i] is not 'MostPopular':\n",
    "        algos[i].fit(trainset)\n",
    "        predictions = algos[i].test(testset)\n",
    "        print(algo_names[i])\n",
    "        performance = get_mae_of_groups(predictions)\n",
    "        performance[\"algo\"] = algo_names[i]\n",
    "        performance_list.append(performance)\n",
    "        all_predictions[algo_names[i]] = predictions\n",
    "\n",
    "    # get top-n items and calculate gaps for all algorithms\n",
    "    if algo_names[i] == 'Random':\n",
    "        top_n = get_top_n_random(testset, n=10)\n",
    "    elif algo_names[i] == 'MostPopular':\n",
    "        top_n = get_top_n_mp(testset, n=10)\n",
    "    else:\n",
    "        top_n = get_top_n(predictions, n=10)\n",
    "    low_count = 0\n",
    "    med_count = 0\n",
    "    high_count = 0\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        iid_list = []\n",
    "        for (iid, _) in user_ratings:\n",
    "            df_item_dist.loc[iid, algo_names[i]] += 1\n",
    "            iid_list.append(iid)\n",
    "        gap = sum(item_dist[iid_list] / no_users) / len(iid_list)\n",
    "        if uid in low_users.index:\n",
    "            low_rec_gap += gap\n",
    "            low_count += 1\n",
    "        elif uid in medium_users.index:\n",
    "            medium_rec_gap += gap\n",
    "            med_count += 1\n",
    "        elif uid in high_users.index:\n",
    "            high_rec_gap += gap\n",
    "            high_count += 1\n",
    "    low_rec_gap_list.append(low_rec_gap / low_count)\n",
    "    medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
    "    high_rec_gap_list.append(high_rec_gap / high_count)\n",
    "    i += 1 # next algorithm\n",
    "\n",
    "performance_data: pd.DataFrame = pd.concat(performance_list)\n",
    "prediction_data: pd.DataFrame = pd.DataFrame(all_predictions)\n",
    "print(performance_data.head())\n",
    "print(prediction_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_data.to_csv(performance_data_file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data.to_csv(prediction_data_file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(algo_names)):\n",
    "    plt.figure()\n",
    "    x = df_item_dist['count']\n",
    "    y = df_item_dist[algo_names[i]]\n",
    "    #slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "    #line = slope * np.array(x) + intercept\n",
    "    #print(r_value)\n",
    "    if algo_names[i] is not 'Random' and algo_names[i] is not 'MostPopular':\n",
    "        plt.gca().set_ylim(0, 300)\n",
    "    plt.plot(x, y, 'o')#, x, line)\n",
    "    plt.xlabel('Artist popularity', fontsize='15')\n",
    "    plt.ylabel('Recommendation frequency', fontsize='15')\n",
    "    plt.xticks(fontsize='13')\n",
    "    plt.yticks(fontsize='13')\n",
    "    #plt.savefig('data/ECIR/rec_' + algo_names[i] + '.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_gap_vals = []\n",
    "medium_gap_vals = []\n",
    "high_gap_vals = []\n",
    "\n",
    "for i in range(0, len(algos)):\n",
    "    low_gap_vals.append((low_rec_gap_list[i] - low_gap) / low_gap * 100)\n",
    "    medium_gap_vals.append((medium_rec_gap_list[i] - medium_gap) / medium_gap * 100)\n",
    "    high_gap_vals.append((high_rec_gap_list[i] - high_gap) / high_gap * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.15\n",
    "\n",
    "# set height of bar\n",
    "bars1 = [low_gap_vals[0], medium_gap_vals[0], high_gap_vals[0]]\n",
    "bars2 = [low_gap_vals[1], medium_gap_vals[1], high_gap_vals[1]]\n",
    "bars3 = [low_gap_vals[2], medium_gap_vals[2], high_gap_vals[2]]\n",
    "bars4 = [low_gap_vals[3], medium_gap_vals[3], high_gap_vals[3]]\n",
    "bars5 = [low_gap_vals[4], medium_gap_vals[4], high_gap_vals[4]]\n",
    "bars6 = [low_gap_vals[5], medium_gap_vals[5], high_gap_vals[5]]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "r5 = [x + barWidth for x in r4]\n",
    "r6 = [x + barWidth for x in r5]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, width=barWidth, label='Random')\n",
    "plt.bar(r2, bars2, width=barWidth, label='MostPopular')\n",
    "plt.bar(r3, bars3, width=barWidth, label='UserItemAvg')\n",
    "plt.bar(r4, bars4, width=barWidth, label='UserKNN')\n",
    "plt.bar(r5, bars5, width=barWidth, label='UserKNNAvg')\n",
    "plt.bar(r6, bars6, width=barWidth, label='NMF')\n",
    "\n",
    "# Add xticks on the middle of the group bars + show legend\n",
    "plt.xlabel('User group', fontsize='15')\n",
    "plt.ylabel('% $\\Delta$ GAP', fontsize='15')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['LowMS', 'MedMS', 'HighMS'], fontsize='13')\n",
    "plt.yticks(fontsize='13')\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0., framealpha=1, fontsize='15')\n",
    "#plt.savefig('data/ECIR/gap_analysis.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c627be1547c7c874688ddee1aaaa67b367275f1752d282bff5eb427acd241334"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
